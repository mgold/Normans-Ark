Extending=========This document serves as a roadmap for those looking to improve thevisualization in its current form, or glean lessons from it to be put towardsanother project.This code was thrown together in a few weeks. In particular, the commentfunctionality (by which witnesses of the uML data are displayed) and thelimitations of processing.js have made the code unwieldy. The ultimate strengthof the project was to abstract out from the witnesses and result code, into whatwe called an error and Norman called an outcome.There are two primary uses of this project. One, to actually discover trends indata sets. For the unit and uML data sets, this is doable; issues with otherdata sets will be described below. Two, to set a high bar for whomever nexttakes up the mantle of visualizing the data. It can be ported to a more robustand extensible implementation, or serve as inspiration for a differentvisualization.We do not advise large changes without overhauling the code, but Norman hasproposed the following feasible tweaks:* The ability to see that a particular test is being moused-over, and which students also have that test failure.* The ability to navigate between tests using the keyboard.  * The bars already have a Cartesian system in place, and could be done relatively easily.  * One would need to devise an algorithm to overlay an orthogonal graph over the circles.* The ability to highlight words in the witnesses. We may be able to fake this by capitalizing LET and LETREC in the uML data.Also on the wishlist is the ability to record arbitrary text associated with thedata. This would be best implemented using HTML text fields and so forth. Itwould also be worthwhile to be able to assign outcomes to categories and renamecategories in the visualization, not in the preprocessor, and for these changesto be saved across page loads. The ability to filter out certain outcomes hasalso been raised. For non-anonymized data, the visualization must either be runlocally or password-protected; this is true to a lesser extent of data thatexposes the tests themselves.The biggest challenge to extending the visualization will be writing thepreprocessor. In most of the remaining datasets, the witness includes multipleerrors separated by semicolons. A test may thus belong to multiple outcomes. Onesolution is to split the small bar representing a single test horizontally,with each band representing an outcome.On the other hand, the Sudoku data does not distinguish between a program thataccepts an incorrect solution and one that rejects a correct solution. Thetesting software needs to be refined in the regard before meaningful dataminingof any sort can be done on that data. In the case of the split-me dataset, onestrategy is to split the data across multiple instances of the visualization.Norman has offered to modify his test code to output to format expected by theparses, making the preprocessor unnecessary. This is worthwhile for a productionimplementation but is probably overkill at the moment. Although Norman hasaccess to the code that procedurally generates the witnesses, we used shellcommands like the following to explore the data files: `grep -v passed path/to/data.file | sed s/\"[^\"]*\"/\"foo\"/g | grep -o "[^ ]* \-\- .*" | sort | uniq`